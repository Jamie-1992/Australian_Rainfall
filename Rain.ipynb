{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                 0\n",
      "Location             0\n",
      "MinTemp           1485\n",
      "MaxTemp           1261\n",
      "Rainfall          3261\n",
      "Evaporation      62790\n",
      "Sunshine         69835\n",
      "WindGustDir      10326\n",
      "WindGustSpeed    10263\n",
      "WindDir9am       10566\n",
      "WindDir3pm        4228\n",
      "WindSpeed9am      1767\n",
      "WindSpeed3pm      3062\n",
      "Humidity9am       2654\n",
      "Humidity3pm       4507\n",
      "Pressure9am      15065\n",
      "Pressure3pm      15028\n",
      "Cloud9am         55888\n",
      "Cloud3pm         59358\n",
      "Temp9am           1767\n",
      "Temp3pm           3609\n",
      "RainToday         3261\n",
      "RainTomorrow      3267\n",
      "dtype: int64\n",
      "(145460, 23)\n",
      "(137153, 23)\n",
      "RainTomorrow\n",
      "0    106884\n",
      "1     30269\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('weatherAUS.csv')\n",
    "print(df.isnull().sum()) \n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "#all features and target have nulls, need to remove for machine learning algorithm to function properly \n",
    "\n",
    "df.dropna(inplace = True, subset = ['MaxTemp', 'Rainfall', 'Humidity3pm', 'RainToday', 'RainTomorrow'])\n",
    "print(df.shape)\n",
    "\n",
    "df['Rain'] = df['RainToday'] == 'Yes' #had to convert to boolean instead of yes/no for it to work. \n",
    "\n",
    "df.RainTomorrow.replace(('No', 'Yes'), (0, 1), inplace=True) #converting target to 0/1\n",
    "\n",
    "\n",
    "X = df[['MaxTemp', 'Rainfall', 'Humidity3pm', 'Rain']].values\n",
    "y = df['RainTomorrow'].values\n",
    "\n",
    "print(df.groupby('RainTomorrow').size()) #this indicates a very inbalanced dataset.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 100)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating decision tree model with 5-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n",
      "--------------------------------------------------\n",
      "precision: 0.5351799838864589\n",
      "recall: 0.4127460478195607\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Note our minority class is Yes it will rain, this is of interest but since the data is very imbalanced,\n",
    "#accuracy is worthless here. I will focus on precision and recall\n",
    "\n",
    "#Note: I initially needed to declare pos_label = 'Yes' in precison and recall functions because it assumes 1 is the positive but \n",
    "#I have yes/no so it automatically wouldn't work. I chose 'yes' to be number 1 by doing this. \n",
    "#I decided to change yes/no to 0/1 in the end\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np \n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 20)\n",
    "dt_precisionScore = []\n",
    "dt_recallScore = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_ypred = dt.predict(X_test)\n",
    "    dt_precisionScore.append(precision_score(y_test, dt_ypred))\n",
    "    dt_recallScore.append(recall_score(y_test, dt_ypred))\n",
    "    \n",
    "print(\"Decision tree\")\n",
    "print(50 *'-')\n",
    "print(\"precision:\", np.mean(dt_precisionScore))\n",
    "print(\"recall:\", np.mean(dt_recallScore))\n",
    "print(50*'-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini and Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree gini\n",
      "precision: 0.5452452923421809\n",
      "recall: 0.41777731138881496\n",
      "Decision Tree entropy\n",
      "precision: 0.5422787014563253\n",
      "recall: 0.41499696604632763\n"
     ]
    }
   ],
   "source": [
    "#default is gini in DecisionTreeClassifier but can set it to entropy as well\n",
    "#going to compare the two\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy')\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 35)\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    print(\"Decision Tree {}\".format(criterion))\n",
    "    dt_precisionScore = []\n",
    "    dt_recallScore = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        dt = DecisionTreeClassifier(criterion = criterion)\n",
    "        dt.fit(X_train, y_train)\n",
    "        dt_ypred = dt.predict(X_test)\n",
    "        dt_precisionScore.append(precision_score(y_test, dt_ypred ))\n",
    "        dt_recallScore.append(recall_score(y_test, dt_ypred))\n",
    "        \n",
    "    print(\"precision:\", np.mean(dt_precisionScore))\n",
    "    print(\"recall:\", np.mean(dt_recallScore))\n",
    "    \n",
    "#essentially the same between entropy and gini\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "####IGNORE####\n",
    "\n",
    "#Creating png image\n",
    "\n",
    "#from sklearn.tree import export_graphviz \n",
    "#import graphviz \n",
    "\n",
    "#X = df[['MaxTemp', 'Rainfall', 'Humidity3pm', 'Rain']].values\n",
    "#y = df['RainTomorrow'].values\n",
    "\n",
    "#dt = DecisionTreeClassifier()\n",
    "#dt.fit(X, y)\n",
    "\n",
    "#dotfile = export_graphviz(dt, feature_names = ['MaxTemp', 'Rainfall', 'Humidity3pm', 'Rain'])\n",
    "#graph = graphviz.Source(dotfile)\n",
    "#graph.render(filename = 'treepic', format = 'png', cleanup = True)\n",
    "#graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters {'max_depth': 10, 'max_leaf_nodes': 40, 'min_samples_leaf': 3}\n",
      "best score 0.522733207389886\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV has 4 parameters we will look at\n",
    "\n",
    "#model which is a decision tree classifier \n",
    "#param grid: dictionary of param names and values\n",
    "#which metric to use \n",
    "#how many folds for cross validation \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramGrid = {\n",
    "    'max_depth': [10,15,20],\n",
    "    'min_samples_leaf': [3, 6],\n",
    "    'max_leaf_nodes': [10,15,25,40]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "gridSearch = GridSearchCV(dt, paramGrid, scoring = 'f1', cv = 5)\n",
    "\n",
    "#fitting gridsearch object to the data \n",
    "\n",
    "gridSearch.fit(X,y)\n",
    "\n",
    "print(\"best parameters\", gridSearch.best_params_)\n",
    "print(\"best score\", gridSearch.best_score_) #score of best model. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
